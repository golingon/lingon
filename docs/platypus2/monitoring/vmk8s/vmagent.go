// Copyright (c) 2023 Volvo Car Corporation
// SPDX-License-Identifier: Apache-2.0

// Code generated by lingon. EDIT AS MUCH AS YOU LIKE.

package vmk8s

import (
	"fmt"

	vmo "github.com/VictoriaMetrics/operator/api/operator/v1"
	ku "github.com/golingon/lingon/pkg/kubeutil"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

var VMAgent = &vmo.VMAgent{
	ObjectMeta: Single.ObjectMetaNameSuffix("vmagent"),
	Spec: vmo.VMAgentSpec{
		ExternalLabels: map[string]string{"cluster": "cluster-name"},
		ExtraArgs:      map[string]string{"promscrape.streamParse": "true"},
		Image:          vmo.Image{Tag: "v" + version},
		RemoteWrite: []vmo.VMAgentRemoteWriteSpec{
			{
				URL: fmt.Sprintf(
					"http://%s.%s.svc:%s/api/v1/write",
					VMDB.PrefixedName(), VMDB.Namespace, VMDB.Spec.Port,
				),
			},
		},
		ScrapeInterval:     "25s",
		SelectAllByDefault: true,
		Resources:          ku.Resources("200m", "128Mi", "200m", "128Mi"),
	},
	TypeMeta: metav1.TypeMeta{
		APIVersion: "operator.victoriametrics.com/vmo",
		Kind:       "VMAgent",
	},
}

var VMAgentAlertRules = &vmo.VMRule{
	ObjectMeta: Single.ObjectMetaNameSuffix("vmagent-alert-rules"),
	Spec: vmo.VMRuleSpec{
		Groups: []vmo.RuleGroup{
			{
				Concurrency: 2,
				Interval:    "30s",
				Name:        "vmagent",
				Rules: []vmo.Rule{
					{
						Alert: "PersistentQueueIsDroppingData",
						Annotations: map[string]string{
							"dashboard":   "grafana.domain.com/d/G7Z9GzMGz?viewPanel=49&var-instance={{ $labels.instance }}",
							"description": "Vmagent dropped {{ $value | humanize1024 }} from persistent queue on instance {{ $labels.instance }} for the last 10m.",
							"summary":     "Instance {{ $labels.instance }} is dropping data from persistent queue",
						},
						Expr:   "sum(increase(vm_persistentqueue_bytes_dropped_total[5m])) by (job, instance) > 0",
						For:    "10m",
						Labels: map[string]string{"severity": "critical"},
					}, {
						Alert: "RejectedRemoteWriteDataBlocksAreDropped",
						Annotations: map[string]string{
							"dashboard": "grafana.domain.com/d/G7Z9GzMGz?viewPanel=79&var-instance={{ $labels.instance }}",
							"summary":   `Job "{{ $labels.job }}" on instance {{ $labels.instance }} drops the rejected by remote-write server data blocks. Check the logs to find the reason for rejects.`,
						},
						Expr:   "sum(increase(vmagent_remotewrite_packets_dropped_total[5m])) by (job, instance) > 0",
						For:    "15m",
						Labels: map[string]string{"severity": "warning"},
					}, {
						Alert: "TooManyScrapeErrors",
						Annotations: map[string]string{
							"dashboard": "grafana.domain.com/d/G7Z9GzMGz?viewPanel=31&var-instance={{ $labels.instance }}",
							"summary":   `Job "{{ $labels.job }}" on instance {{ $labels.instance }} fails to scrape targets for last 15m`,
						},
						Expr:   "sum(increase(vm_promscrape_scrapes_failed_total[5m])) by (job, instance) > 0",
						For:    "15m",
						Labels: map[string]string{"severity": "warning"},
					}, {
						Alert: "TooManyWriteErrors",
						Annotations: map[string]string{
							"dashboard": "grafana.domain.com/d/G7Z9GzMGz?viewPanel=77&var-instance={{ $labels.instance }}",
							"summary":   `Job "{{ $labels.job }}" on instance {{ $labels.instance }} responds with errors to write requests for last 15m.`,
						},
						Expr: `
(sum(increase(vm_ingestserver_request_errors_total[5m])) by (job, instance)
+
sum(increase(vmagent_http_request_errors_total[5m])) by (job, instance)) > 0
`,
						For:    "15m",
						Labels: map[string]string{"severity": "warning"},
					}, {
						Alert: "TooManyRemoteWriteErrors",
						Annotations: map[string]string{
							"dashboard": "grafana.domain.com/d/G7Z9GzMGz?viewPanel=61&var-instance={{ $labels.instance }}",
							"description": `
Vmagent fails to push data via remote write protocol to destination "{{ $labels.url }}"
 Ensure that destination is up and reachable.
`,
							"summary": `Job "{{ $labels.job }}" on instance {{ $labels.instance }} fails to push to remote storage`,
						},
						Expr:   "sum(rate(vmagent_remotewrite_retries_count_total[5m])) by(job, instance, url) > 0",
						For:    "15m",
						Labels: map[string]string{"severity": "warning"},
					}, {
						Alert: "RemoteWriteConnectionIsSaturated",
						Annotations: map[string]string{
							"dashboard":   "grafana.domain.com/d/G7Z9GzMGz?viewPanel=84&var-instance={{ $labels.instance }}",
							"description": "The remote write connection between vmagent \"{{ $labels.job }}\" (instance {{ $labels.instance }}) and destination \"{{ $labels.url }}\" is saturated by more than 90% and vmagent won't be able to keep up.\n This usually means that `-remoteWrite.queues` command-line flag must be increased in order to increase the number of connections per each remote storage.",
							"summary":     `Remote write connection from "{{ $labels.job }}" (instance {{ $labels.instance }}) to {{ $labels.url }} is saturated`,
						},
						Expr: `
sum(rate(vmagent_remotewrite_send_duration_seconds_total[5m])) by(job, instance, url) 
> 0.9 * max(vmagent_remotewrite_queues) by(job, instance, url)
`,
						For:    "15m",
						Labels: map[string]string{"severity": "warning"},
					}, {
						Alert: "PersistentQueueForWritesIsSaturated",
						Annotations: map[string]string{
							"dashboard":   "grafana.domain.com/d/G7Z9GzMGz?viewPanel=98&var-instance={{ $labels.instance }}",
							"description": `Persistent queue writes for vmagent "{{ $labels.job }}" (instance {{ $labels.instance }}) are saturated by more than 90% and vmagent won't be able to keep up with flushing data on disk. In this case, consider to decrease load on the vmagent or improve the disk throughput.`,
							"summary":     "Persistent queue writes for instance {{ $labels.instance }} are saturated",
						},
						Expr:   "rate(vm_persistentqueue_write_duration_seconds_total[5m]) > 0.9",
						For:    "15m",
						Labels: map[string]string{"severity": "warning"},
					}, {
						Alert: "PersistentQueueForReadsIsSaturated",
						Annotations: map[string]string{
							"dashboard":   "grafana.domain.com/d/G7Z9GzMGz?viewPanel=99&var-instance={{ $labels.instance }}",
							"description": `Persistent queue reads for vmagent "{{ $labels.job }}" (instance {{ $labels.instance }}) are saturated by more than 90% and vmagent won't be able to keep up with reading data from the disk. In this case, consider to decrease load on the vmagent or improve the disk throughput.`,
							"summary":     "Persistent queue reads for instance {{ $labels.instance }} are saturated",
						},
						Expr:   "rate(vm_persistentqueue_read_duration_seconds_total[5m]) > 0.9",
						For:    "15m",
						Labels: map[string]string{"severity": "warning"},
					}, {
						Alert: "SeriesLimitHourReached",
						Annotations: map[string]string{
							"dashboard":   "grafana.domain.com/d/G7Z9GzMGz?viewPanel=88&var-instance={{ $labels.instance }}",
							"description": "Max series limit set via -remoteWrite.maxHourlySeries flag is close to reaching the max value. Then samples for new time series will be dropped instead of sending them to remote storage systems.",
							"summary":     "Instance {{ $labels.instance }} reached 90% of the limit",
						},
						Expr:   "(vmagent_hourly_series_limit_current_series / vmagent_hourly_series_limit_max_series) > 0.9",
						Labels: map[string]string{"severity": "critical"},
					}, {
						Alert: "SeriesLimitDayReached",
						Annotations: map[string]string{
							"dashboard":   "grafana.domain.com/d/G7Z9GzMGz?viewPanel=90&var-instance={{ $labels.instance }}",
							"description": "Max series limit set via -remoteWrite.maxDailySeries flag is close to reaching the max value. Then samples for new time series will be dropped instead of sending them to remote storage systems.",
							"summary":     "Instance {{ $labels.instance }} reached 90% of the limit",
						},
						Expr:   "(vmagent_daily_series_limit_current_series / vmagent_daily_series_limit_max_series) > 0.9",
						Labels: map[string]string{"severity": "critical"},
					}, {
						Alert: "ConfigurationReloadFailure",
						Annotations: map[string]string{
							"description": "Configuration hot-reload failed for vmagent on instance {{ $labels.instance }}. Check vmagent's logs for detailed error message.",
							"summary":     "Configuration reload failed for vmagent instance {{ $labels.instance }}",
						},
						Expr: `
vm_promscrape_config_last_reload_successful != 1
or
vmagent_relabel_config_last_reload_successful != 1
`,
						Labels: map[string]string{"severity": "warning"},
					},
				},
			},
		},
	},
	TypeMeta: TypeVMRulevmo,
}
